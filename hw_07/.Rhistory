library(dplyr)
library(ggplot2)
library(highcharter)
library(readr)
library(psych)
library(corrplot)
library(car)
library(mgcv)
library(caret)
library(e1071)
library(pROC)
library(ROCR)
library(h2o)
library(data.table)
library(scales)
library(grid)
library(gridExtra)
library(tidyr)
murder_suicide = read.csv("../../Data/murder_suicide/murder_suicide.csv")
murder_suicide %>%
mutate(Education = ifelse(EducationReportingFlag, Education2003Revision ,ifelse(-1<Education1989Revision && Education1989Revision<9,1,ifelse(8<Education1989Revision && Education1989Revision<12, 2, ifelse(Education1989Revision == 12, 3, ifelse(12<Education1989Revision && Education1989Revision<16,4,ifelse(Education1989Revision == 99, 9, 5))))))) %>% # transform 1080 to standard 2003 Education degrees
mutate(Disposition = ifelse(MethodOfDisposition == 'U', 0 , ifelse(MethodOfDisposition == 'O', 1 , ifelse(MethodOfDisposition == 'B', 2 , 3)))) %>% # transform disposition to numeric
mutate(InjuryAtWork = ifelse(InjuryAtWork == 'Y', 1, ifelse(InjuryAtWork == 'N', 0, -1))) %>%
mutate(Sex = ifelse(Sex == 'M', 1, 0) ) %>%
mutate(MannerOfDeath = ifelse(MannerOfDeath == 2, 1, 0)) %>%
select(ActivityCode, AgeRecode12, DayOfWeekOfDeath, Education, HispanicOriginRaceRecode, Disposition, PlaceOfDeathAndDecedentsStatus, PlaceOfInjury, RaceRecode3, ResidentStatus, MonthOfDeath, Sex, CauseRecode39 ,MannerOfDeath) -> selected_ms # selected param.
# plot selected param.
cor_ms = cor(selected_ms)
corrplot(cor_ms, method = "square", type = "lower", tl.col = "black", tl.srt = 10, tl.cex = 0.8)
# find top 10 cor.
knitr::kable(abs(sort(-abs(cor_ms['MannerOfDeath',]))[2:11]))
top_10_cor = selected_ms %>%
select(RaceRecode3,CauseRecode39,AgeRecode12,PlaceOfInjury,Education,ActivityCode,Disposition,ResidentStatus,PlaceOfDeathAndDecedentsStatus,Sex)
dist_samp = sample_frac(top_10_cor, 0.1)
# distribution matrix plot for 10% sample of top 10 cor.
scatterplotMatrix(dist_samp, regLine = list(method=lm, lty=1, col="red") ,smooth=list(smoother=loessLine, spread=FALSE, lty.smooth=2, col.smooth="black"), col = "gray")
# Sex
s = cor.test(selected_ms$Sex, selected_ms$MannerOfDeath, method = 'spearman')
print(s)
# Race
r = cor.test(selected_ms$RaceRecode3, selected_ms$MannerOfDeath, method = 'spearman')
print(r)
# Education
e = cor.test(selected_ms$Education, selected_ms$MannerOfDeath, method = 'spearman')
print(e)
# Age
a = cor.test(selected_ms$AgeRecode12, selected_ms$MannerOfDeath, method = 'spearman')
print(a)
# Disposition
d = cor.test(selected_ms$Disposition, selected_ms$MannerOfDeath, method = 'spearman')
print(d)
rml = glm(MannerOfDeath~., family = binomial(link = 'logit'), data = selected_ms)
summary(rml)
AccuracyCutoffInfo <- function( train, test, predict, actual )
{
# change the cutoff value's range as you please
cutoff <- seq( .3, .9, by = .01 )
accuracy <- lapply( cutoff, function(c)
{
# use the confusionMatrix from the caret package
cm_train <- confusionMatrix( as.numeric( train[[predict]] > c ), train[[actual]] )
cm_test  <- confusionMatrix( as.numeric( test[[predict]]  > c ), test[[actual]]  )
dt <- data.table( cutoff = c,
train  = cm_train$overall[["Accuracy"]],
test   = cm_test$overall[["Accuracy"]] )
return(dt)
}) %>% rbindlist()
# visualize the accuracy of the train and test set for different cutoff value
# accuracy in percentage.
accuracy_long <- gather( accuracy, "data", "accuracy", -1 )
plot <- ggplot( accuracy_long, aes( cutoff, accuracy, group = data, color = data ) ) +
geom_line( size = 1 ) + geom_point( size = 3 ) +
scale_y_continuous( label = percent ) +
ggtitle( "Train/Test Accuracy for Different Cutoff" )
return( list( data = accuracy, plot = plot ) )
}
ConfusionMatrixInfo <- function( data, predict, actual, cutoff )
{
# extract the column ;
# relevel making 1 appears on the more commonly seen position in
# a two by two confusion matrix
predict <- data[[predict]]
actual  <- relevel( as.factor( data[[actual]] ), "1" )
result <- data.table( actual = actual, predict = predict )
# caculating each pred falls into which category for the confusion matrix
result[ , type := ifelse( predict >= cutoff & actual == 1, "TP",
ifelse( predict >= cutoff & actual == 0, "FP",
ifelse( predict <  cutoff & actual == 1, "FN", "TN" ) ) ) %>% as.factor() ]
# jittering : can spread the points along the x axis
plot <- ggplot( result, aes( actual, predict, color = type ) ) +
geom_violin( fill = "white", color = NA ) +
geom_jitter( shape = 1 ) +
geom_hline( yintercept = cutoff, color = "blue", alpha = 0.6 ) +
scale_y_continuous( limits = c( 0, 1 ) ) +
scale_color_discrete( breaks = c( "TP", "FN", "FP", "TN" ) ) + # ordering of the legend
guides( col = guide_legend( nrow = 2 ) ) + # adjust the legend to have two rows
ggtitle( sprintf( "Confusion Matrix with Cutoff at %.2f", cutoff ) )
return( list( data = result, plot = plot ) )
}
ROCInfo <- function( data, predict, actual, cost.fp, cost.fn )
{
# calculate the values using the ROCR library
# true positive, false postive
pred <- prediction( data[[predict]], data[[actual]] )
perf <- performance( pred, "tpr", "fpr" )
roc_dt <- data.frame( fpr = perf@x.values[[1]], tpr = perf@y.values[[1]] )
# cost with the specified false positive and false negative cost
# false postive rate * number of negative instances * false positive cost +
# false negative rate * number of positive instances * false negative cost
cost <- perf@x.values[[1]] * cost.fp * sum( data[[actual]] == 0 ) +
( 1 - perf@y.values[[1]] ) * cost.fn * sum( data[[actual]] == 1 )
cost_dt <- data.frame( cutoff = pred@cutoffs[[1]], cost = cost )
# optimal cutoff value, and the corresponding true positive and false positive rate
best_index  <- which.min(cost)
best_cost   <- cost_dt[ best_index, "cost" ]
best_tpr    <- roc_dt[ best_index, "tpr" ]
best_fpr    <- roc_dt[ best_index, "fpr" ]
best_cutoff <- pred@cutoffs[[1]][ best_index ]
# area under the curve
auc <- performance( pred, "auc" )@y.values[[1]]
# normalize the cost to assign colors to 1
normalize <- function(v) ( v - min(v) ) / diff( range(v) )
# create color from a palette to assign to the 100 generated threshold between 0 ~ 1
# then normalize each cost and assign colors to it, the higher the blacker
# don't times it by 100, there will be 0 in the vector
col_ramp <- colorRampPalette( c( "green", "orange", "red", "black" ) )(100)
col_by_cost <- col_ramp[ ceiling( normalize(cost) * 99 ) + 1 ]
roc_plot <- ggplot( roc_dt, aes( fpr, tpr ) ) +
geom_line( color = rgb( 0, 0, 1, alpha = 0.3 ) ) +
geom_point( color = col_by_cost, size = 4, alpha = 0.2 ) +
geom_segment( aes( x = 0, y = 0, xend = 1, yend = 1 ), alpha = 0.8, color = "royalblue" ) +
labs( title = "ROC", x = "False Postive Rate", y = "True Positive Rate" ) +
geom_hline( yintercept = best_tpr, alpha = 0.8, linetype = "dashed", color = "steelblue4" ) +
geom_vline( xintercept = best_fpr, alpha = 0.8, linetype = "dashed", color = "steelblue4" )
cost_plot <- ggplot( cost_dt, aes( cutoff, cost ) ) +
geom_line( color = "blue", alpha = 0.5 ) +
geom_point( color = col_by_cost, size = 4, alpha = 0.5 ) +
ggtitle( "Cost" ) +
scale_y_continuous( labels = comma ) +
geom_vline( xintercept = best_cutoff, alpha = 0.8, linetype = "dashed", color = "steelblue4" )
# the main title for the two arranged plot
sub_title <- sprintf( "Cutoff at %.2f - Total Cost = %f, AUC = %.3f",
best_cutoff, best_cost, auc )
# arranged into a side by side plot
plot <- arrangeGrob( roc_plot, cost_plot, ncol = 2,
top = textGrob( sub_title, gp = gpar( fontsize = 16, fontface = "bold" ) ) )
return( list( plot 		  = plot,
cutoff 	  = best_cutoff,
totalcost   = best_cost,
auc         = auc,
sensitivity = best_tpr,
specificity = 1 - best_fpr ) )
}
pred_res_f <- fitted(rml, newdata=selected_ms, type='response')
ggplot(selected_ms, aes(pred_res_f, color = as.factor(MannerOfDeath))) +
geom_density(size = 1) +
ggtitle("Full Set's Predicted Score") +
xlab("Prediction")
table(selected_ms$MannerOfDeath,ifelse(pred_res_f>0.5,1,0)) %>%
plot(xlab = "Prediction", ylab = "Data") %>%
title(main = "Real vs Predicted")
selected_ms['Prediction'] = pred_res_f
cm_info = ConfusionMatrixInfo(data = selected_ms, predict = "Prediction",
actual = "MannerOfDeath", cutoff = .5 )
cm_info$plot
pred_res_f <- ifelse(pred_res_f>0.5,1,0)
cm = table(pred_res_f, selected_ms$MannerOfDeath)
cm = confusionMatrix(cm)
print(cm)
set.seed(NULL)
smp_size <- floor(0.8 * nrow(selected_ms))
train_ind <- sample(seq_len(nrow(selected_ms)), size = smp_size)
train <- selected_ms[train_ind, ]
test <- selected_ms[-train_ind, ]
test_t <- test %>% select(-MannerOfDeath)
rml_new = glm(MannerOfDeath~., data = train, family = binomial(link = 'logit'))
pred_res = 0
pred_res <- predict(rml_new, newdata=test_t, type='response')
pred_res <- ifelse(pred_res > 0.5, 1, 0)
test['Prediction'] = pred_res
P = nrow(test %>% filter(MannerOfDeath == 1))
print(P)
N = nrow(test) - P
print(N)
TP = nrow(test %>% filter(MannerOfDeath == 1 & Prediction == 1))
print(TP)
TN = nrow(test %>% filter(MannerOfDeath == 0 & Prediction == 0))
print(TN)
FP = nrow(test %>% filter(MannerOfDeath == 0 & Prediction == 1))
print(FP)
FN = nrow(test %>% filter(MannerOfDeath == 1 & Prediction == 0))
print(FN)
ACC = (TP+TN)/(P+N)
print(ACC)
FPR = 1 - TN/N
print(FPR)
TPR = TP/P
print(TPR)
pred_res <- predict(rml_new, newdata=test_t, type='response')
test['Prediction'] = pred_res
cm_info = ConfusionMatrixInfo(data = test, predict = "Prediction",
actual = "MannerOfDeath", cutoff = .5 )
cm_info$plot
res = vector('integer',1000)
max = -1000
maxi = 0
for(i in 1:1000){
pred_res_t = predict(rml_new, newdata=test_t, type='response')
pred_res_t = ifelse(pred_res_t > (i/1000), 1, 0)
test['Prediction'] = pred_res_t
P_t = nrow(test %>% filter(MannerOfDeath == 1))
N_t = nrow(test) - P_t
TP_t = nrow(test %>% filter(MannerOfDeath == 1 & Prediction == 1))
TN_t = nrow(test %>% filter(MannerOfDeath == 0 & Prediction == 0))
ACC_t = (TP_t + TN_t)/(P_t + N_t)
if(ACC_t > max){
max = ACC_t
maxi = i/1000
}
res[i] = ACC_t
}
# max acc index (cutoff)
print(maxi)
plot(res, xlab = "Cut (1000x)", ylab = "Accuracy")
cost_fp = 100;cost_fn = 200
roc_info = ROCInfo(data = cm_info$data, predict = "predict",
actual = "actual", cost.fp = cost_fp, cost.fn = cost_fn)
plot(roc_info$plot)
h2o.init(ip = "localhost", max_mem_size = "2g")
ms_h2o_train <- as.h2o(train)
ms_h2o_test <- as.h2o(test)
Y <- "MannerOfDeath"
X <- c("ActivityCode","AgeRecode12","DayOfWeekOfDeath","Education","HispanicOriginRaceRecode","Disposition","PlaceOfDeathAndDecedentsStatus","PlaceOfInjury","RaceRecode3","ResidentStatus","MonthOfDeath","Sex","CauseRecode39")
dist <- "binomial"
link <- "logit"
id <- "h2o_mdl"
mdl <- h2o.glm(X, Y, training_frame = ms_h2o_train, model_id = id, family = dist, link = link, lambda = 0, compute_p_values = TRUE, standardize = FALSE, nfolds = 5)
show(h2o.getModel(id)@model$coefficients_table)
summary(mdl)
fit_h2o = h2o.predict(mdl, newdata = ms_h2o_test)
summary(fit_h2o)
